import os
import json
import pandas as pd
import requests
from io import BytesIO
from datetime import datetime, timedelta
from google.oauth2 import service_account
from googleapiclient.discovery import build

# ===================== Autenticar com Google APIs =====================
json_secret = os.getenv("GDRIVE_SERVICE_ACCOUNT")
credentials_info = json.loads(json_secret)
scopes = ["https://www.googleapis.com/auth/drive", "https://www.googleapis.com/auth/spreadsheets"]
credentials = service_account.Credentials.from_service_account_info(credentials_info, scopes=scopes)
drive_service = build("drive", "v3", credentials=credentials)
sheets_service = build("sheets", "v4", credentials=credentials)

# ===================== Configura√ß√µes =====================
export_url = "https://services.contaazul.com/finance-pro-reports/api/v1/installment-view/export"
headers = {
    'x-authorization': '0779e4c7-5a95-48e7-a838-a7aa443f4fd7',
    'Content-Type': 'application/json',
    'User-Agent': 'Mozilla/5.0'
}

# Lista de status para processar
status_list = ["ACQUITTED", "PARTIAL", "PENDING", "LOST"]

# ===================== Baixar e consolidar arquivos XLSX =====================
print("üîÑ Iniciando download dos arquivos XLSX para cada status...")

all_dataframes = []

for status_atual in status_list:
    print(f"\nüì• Baixando dados para status: {status_atual}")

    payload = json.dumps({
        "dueDateFrom": None,
        "dueDateTo": None,
        "quickFilter": "ALL",
        "search": "",
        "status": [status_atual],
        "type": "REVENUE"
    })

    try:
        response = requests.post(export_url, headers=headers, data=payload)
        response.raise_for_status()

        # Ler o arquivo XLSX da resposta
        xlsx_content = BytesIO(response.content)
        df = pd.read_excel(xlsx_content)

        # Adicionar coluna de status
        df['status'] = status_atual

        print(f"  ‚úÖ {len(df)} registros baixados para {status_atual}")

        all_dataframes.append(df)

    except requests.exceptions.RequestException as e:
        print(f"  ‚ö†Ô∏è Erro ao baixar dados para {status_atual}: {e}")
        continue
    except Exception as e:
        print(f"  ‚ö†Ô∏è Erro ao processar arquivo XLSX para {status_atual}: {e}")
        continue

# ===================== Consolidar todos os DataFrames =====================
if not all_dataframes:
    raise Exception("‚ùå Nenhum dado foi baixado com sucesso!")

print(f"\nüîÑ Consolidando {len(all_dataframes)} arquivos...")
df_consolidado = pd.concat(all_dataframes, ignore_index=True)

# Remover duplicatas baseadas no ID (se existir coluna 'id')
if 'id' in df_consolidado.columns:
    df_consolidado = df_consolidado.drop_duplicates(subset=['id'], keep='first')
    print(f"üìã Total de registros √∫nicos ap√≥s remo√ß√£o de duplicatas: {len(df_consolidado)}")
else:
    print(f"üìã Total de registros consolidados: {len(df_consolidado)}")

# ===================== Atualizar status PENDING para OVERDUE =====================
print(f"\nüîÑ Verificando status PENDING com data vencida...")

# Calcular data de ontem
ontem = datetime.now() - timedelta(days=1)
ontem = ontem.replace(hour=0, minute=0, second=0, microsecond=0)

# Nome da coluna de data de vencimento (ajuste se necess√°rio)
col_vencimento = "Data de vencimento"

if col_vencimento in df_consolidado.columns:
    # Converter coluna de vencimento para datetime
    df_consolidado[col_vencimento] = pd.to_datetime(df_consolidado[col_vencimento], format='%d/%m/%Y', errors='coerce', dayfirst=True)

    # Contar quantos ser√£o atualizados
    mask_update = (df_consolidado['status'] == 'PENDING') & (df_consolidado[col_vencimento] <= ontem)
    total_atualizados = mask_update.sum()

    # Atualizar status
    df_consolidado.loc[mask_update, 'status'] = 'OVERDUE'

    print(f"  ‚úÖ {total_atualizados} registros PENDING atualizados para OVERDUE")
else:
    print(f"  ‚ö†Ô∏è AVISO: Coluna '{col_vencimento}' n√£o encontrada!")
    print(f"  Colunas dispon√≠veis: {df_consolidado.columns.tolist()}")

# ===================== Criar nova coluna com valor calculado =====================
print(f"\nüîÑ Criando coluna 'Valor Calculado'...")

# Nomes das colunas para contas a receber
col_recebido = "Valor total recebido da parcela (R$)"
col_aberto = "Valor da parcela em aberto (R$)"

# Garantir que as colunas existam
if col_recebido not in df_consolidado.columns or col_aberto not in df_consolidado.columns:
    print(f"  ‚ö†Ô∏è AVISO: Colunas esperadas n√£o encontradas!")
    print(f"  Colunas dispon√≠veis: {df_consolidado.columns.tolist()}")
else:
    # Criar a nova coluna baseada nas condi√ß√µes
    def calcular_valor(row):
        if row['status'] == 'ACQUITTED':
            # Se ACQUITTED, considerar apenas valor recebido
            return row[col_recebido]
        elif row['status'] == 'PARTIAL':
            # Se PARTIAL, somar valor recebido + valor em aberto
            return row[col_recebido] + row[col_aberto]
        else:
            # Para outros status (PENDING, OVERDUE, LOST), considerar valor em aberto
            return row[col_aberto]

    df_consolidado['Valor Calculado'] = df_consolidado.apply(calcular_valor, axis=1)
    print(f"  ‚úÖ Coluna 'Valor Calculado' criada com sucesso!")

# ===================== Converter colunas datetime para string =====================
print(f"\nüîÑ Convertendo colunas de data para string...")

# Identificar colunas de tipo datetime
datetime_columns = df_consolidado.select_dtypes(include=['datetime64']).columns.tolist()

# Converter cada coluna datetime para string no formato desejado
for col in datetime_columns:
    df_consolidado[col] = df_consolidado[col].dt.strftime('%d/%m/%Y')
    print(f"  ‚úÖ Coluna '{col}' convertida para string")

# ===================== Renomear colunas conforme especifica√ß√£o =====================
print(f"\nüîÑ Renomeando colunas...")

# Dicion√°rio de mapeamento: nome_antigo -> nome_novo
colunas_renomear = {
    "Data de vencimento": "dueDate",
    "Data de compet√™ncia": "financialEvent.competenceDate",
    "Valor Calculado": "paid",
    "Categoria 1": "categoriesRatio.category",
    "Descri√ß√£o": "description",
    "Nome do cliente": "financialEvent.negotiator.name",
    "Data do √∫ltimo pagamento": "lastAcquittanceDate"
}

# Renomear apenas as colunas que existem no DataFrame
colunas_renomeadas = {}
for col_antiga, col_nova in colunas_renomear.items():
    if col_antiga in df_consolidado.columns:
        colunas_renomeadas[col_antiga] = col_nova
        print(f"  ‚úÖ '{col_antiga}' ‚Üí '{col_nova}'")
    else:
        print(f"  ‚ö†Ô∏è Coluna '{col_antiga}' n√£o encontrada")

df_consolidado.rename(columns=colunas_renomeadas, inplace=True)

# ===================== Buscar ID da planilha no Google Drive =====================
folder_id = "18MfMQN_Z5zaxqlGFbEh9qBTCIz-BbCg_"
sheet_name = "FInanceiro_contas_a_receber_Teste"

query = f"name='{sheet_name}' and mimeType='application/vnd.google-apps.spreadsheet' and '{folder_id}' in parents and trashed=false"
results = drive_service.files().list(q=query, spaces='drive', fields="files(id, name)").execute()
files = results.get("files", [])

if not files:
    raise Exception(f"Planilha '{sheet_name}' n√£o encontrada na pasta do Drive.")

spreadsheet_id = files[0]['id']

# ===================== Limpar conte√∫do anterior da planilha =====================
print(f"\nüßπ Limpando planilha '{sheet_name}'...")
sheets_service.spreadsheets().values().clear(
    spreadsheetId=spreadsheet_id,
    range="A:BA"
).execute()

# ===================== Atualizar dados na planilha =====================
print(f"üì§ Atualizando planilha com {len(df_consolidado)} registros...")
values = [df_consolidado.columns.tolist()] + df_consolidado.fillna("").values.tolist()
sheets_service.spreadsheets().values().update(
    spreadsheetId=spreadsheet_id,
    range="A1",
    valueInputOption="USER_ENTERED",
    body={"values": values}
).execute()

print(f"\n‚úÖ Planilha Google '{sheet_name}' atualizada com sucesso!")
print(f"üìä Total de registros: {len(df_consolidado)}")
print(f"üìä Registros por status (ap√≥s ajustes):")
for status in status_list + ['OVERDUE']:
    count = len(df_consolidado[df_consolidado['status'] == status])
    if count > 0:
        print(f"  - {status}: {count} registros")
